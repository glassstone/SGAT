# [MIA 2023] SGAT
![](https://ars.els-cdn.com/content/image/1-s2.0-S1361841523001895-ga1_lrg.jpg)
![](https://ars.els-cdn.com/content/image/1-s2.0-S1361841523001895-gr6_lrg.jpg)
> Inspired by the way that the visual cortex adaptively responds to the type of stimulus, the Stimulus-guided adaptive transformer(SGAT) network is proposed to produce the local-and-global compound features based on inductive bias and self-attention mechanism to take into account the vascular details and anatomy structures. The evaluation is implemented on the largest fundus image dataset (FIVES) and three popular retinal image datasets (DRIVE, STARE, CHASEDB1) and experimental results show that the proposed method achieves a competitive performance over the other existing method.

> This repo implementation is based on PyTorch. More details can be found in [Paper](https://doi.org/10.1016/j.media.2023.102929)

# Citation
> If you find this paper useful, please use the following BibTeX entry to cite our paper:

```
@article{lin2023stimulus,
  title={Stimulus-guided adaptive transformer network for retinal blood vessel segmentation in fundus images},
  author={Lin, Ji and Huang, Xingru and Zhou, Huiyu and Wang, Yaqi and Zhang, Qianni},
  journal={Medical Image Analysis},
  pages={102929},
  year={2023},
  publisher={Elsevier}
}
```
